{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e490d4",
   "metadata": {},
   "source": [
    "## Random Forest - One parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a131551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_numpoints = 5000\n",
    "end_numpoints = 50000\n",
    "interval = 1000\n",
    "\n",
    "results = []\n",
    "\n",
    "for numpoints in range(start_numpoints, end_numpoints + 1, interval):\n",
    "    start_time = time.time()\n",
    "    print(f\"Number of Points: {numpoints}\")\n",
    "\n",
    "    data = pd.read_csv(f'datasets/Energy/fuchs_v3_points_{numpoints}_noise_10.csv')\n",
    "\n",
    "    features = data[['Intensity_(W_cm2)', 'Target_Thickness (um)', 'Focal_Distance_(um)']]\n",
    "    target = data[['Max_Proton_Energy_(MeV)']]\n",
    "\n",
    "    features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the Random Forest Regressor\n",
    "    rf = RandomForestRegressor(n_estimators=400, max_depth=20, min_samples_split=2, min_samples_leaf=1, max_features='auto', random_state=42)\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    rf.fit(features_train, target_train.values.ravel())\n",
    "\n",
    "    # Predict on the test set\n",
    "    target_test_pred = rf.predict(features_test)\n",
    "\n",
    "    # Calculate the MSE\n",
    "    mse_error = mean_squared_error(target_test, target_test_pred)\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    rmse_error = np.sqrt(mse_error)\n",
    "\n",
    "    # Calculate the ARE in percentage\n",
    "    are_error = (mean_absolute_error(target_test, target_test_pred) / np.mean(target_test, axis=0)) * 100\n",
    "\n",
    "    # Extract the scalar value from the Series object\n",
    "    are_error_scalar = are_error.values.item()\n",
    "\n",
    "    # Format the ARE to display as a percentage with two decimal places\n",
    "    are_error_formatted = \"{:.2f}%\".format(are_error_scalar)\n",
    "\n",
    "    # Store the results in a dictionary\n",
    "    result = {\n",
    "        'Number of Points': numpoints,\n",
    "        'MSE': mse_error,\n",
    "        'RMSE': rmse_error,\n",
    "        'ARE': are_error_scalar,\n",
    "        'Elapsed Time (seconds)': time.time() - start_time\n",
    "    }\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "    print(f'MSE: {mse_error}')\n",
    "    print(f'RMSE: {rmse_error}')\n",
    "    print(f'ARE: {are_error_formatted}')\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c34bbc4",
   "metadata": {},
   "source": [
    "## Random Forest - Three Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_numpoints = 5000\n",
    "end_numpoints = 50000\n",
    "interval = 1000\n",
    "\n",
    "results = []\n",
    "\n",
    "for numpoints in range(start_numpoints, end_numpoints + 1, interval):\n",
    "    start_time = time.time()\n",
    "    print(f\"Number of Points: {numpoints}\")\n",
    "\n",
    "    data = pd.read_csv(f'datasets/Energy/fuchs_v3_points_{numpoints}_noise_10.csv')\n",
    "    features = data[['Intensity_(W_cm2)', 'Target_Thickness (um)', 'Focal_Distance_(um)']]\n",
    "    target = data[['Max_Proton_Energy_(MeV)', 'Avg_Proton_Energy_(MeV)', 'Total_Proton_Energy_(MeV)']]\n",
    "\n",
    "    # Split the dataset into train and test sets\n",
    "    features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the hyperparameter grid to search\n",
    "    param_grid = {\n",
    "        'n_estimators': [400],\n",
    "        'max_depth': [20],\n",
    "        'min_samples_split': [2],\n",
    "        'min_samples_leaf': [1],\n",
    "        'max_features': ['auto'],\n",
    "    }\n",
    "\n",
    "    # Initialize the Random Forest Regressor\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "    # Perform grid search to find the best hyperparameters\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(features_train, target_train)\n",
    "\n",
    "    # Get the best model from the grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predict on the test set using the best model\n",
    "    target_test_pred = best_model.predict(features_test)\n",
    "\n",
    "    # Calculate the MSE, RMSE, and ARE for each target variable\n",
    "    mse_errors = []\n",
    "    rmse_errors = []\n",
    "    are_errors = []\n",
    "    for i, column in enumerate(target.columns):\n",
    "        mse_error = mean_squared_error(target_test[column], target_test_pred[:, i])\n",
    "        rmse_error = np.sqrt(mse_error)\n",
    "        are_error = (mean_absolute_error(target_test[column], target_test_pred[:, i]) / np.mean(target_test[column])) * 100\n",
    "        mse_errors.append(mse_error)\n",
    "        rmse_errors.append(rmse_error)\n",
    "        are_errors.append(are_error)\n",
    "\n",
    "    # Store the results in a dictionary\n",
    "    result = {\n",
    "        'Number of Points': numpoints,\n",
    "        'MSE Max_Proton_Energy': mse_errors[0],\n",
    "        'RMSE Max_Proton_Energy': rmse_errors[0],\n",
    "        'ARE Max_Proton_Energy': are_errors[0],\n",
    "        'Elapsed Time (seconds)': time.time() - start_time\n",
    "    }\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "    # Print the MSE, RMSE, and ARE for each target variable\n",
    "    for i, column in enumerate(target.columns):\n",
    "        print(f'MSE for {column}: {mse_errors[i]}')\n",
    "        print(f'RMSE for {column}: {rmse_errors[i]}')\n",
    "        print(f'ARE for {column}: {are_errors[i]}%')\n",
    "\n",
    "    # Print the best hyperparameters from the grid search\n",
    "    print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('results.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
